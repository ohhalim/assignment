{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e3d3a36",
   "metadata": {},
   "source": [
    "**트러블 슈팅** \n",
    "제가 참고코드를 잘 이해 못 합니다.\n",
    "그래서 이번 필수과제에 대해서 제가 중점으로 생각한 것은 코드 이해입니다. 이해를 하기 위해 코드에 주석을 달았습니다.\n",
    "또 문제점이 만들었지만 프롬프트에 적은 내용이 잘 적용이 되지 않는 것 같습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "978e57af-3508-4923-b526-2cf9b2a4b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "사용환경 준비\n",
    "원하는 모델에 따른 사용 환경을 준비\n",
    "\"\"\"\n",
    "\n",
    "import os \n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key 입력: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996003aa-ca9f-44f2-a7bf-6be929d0cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "모델 로드하기 \n",
    "OpenAI 로드 모델에 저장\n",
    "\"\"\"\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage      \n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3cda84-4e45-41c4-baf8-2bfd08e50879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (5.1.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "문서 로드하기\n",
    "langchain의 PyPDFLoader를 이용하여 문서를 불러오기\n",
    "\"\"\"\n",
    "\n",
    "!pip install pypdf\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 경로 지정\n",
    "\n",
    "pdf_path = \"/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf\"\n",
    "#file_path: PDF 파일 경로 \n",
    "\n",
    "# pypdfloder 생성\n",
    "loader  = PyPDFLoader(pdf_path)\n",
    "\n",
    "# pdf 파일 로드\n",
    "pages = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfd8e9f-0ac0-4b4b-9f40-10a597c027ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1674, which is longer than the specified 100\n",
      "Created a chunk of size 224, which is longer than the specified 100\n",
      "Created a chunk of size 214, which is longer than the specified 100\n",
      "Created a chunk of size 214, which is longer than the specified 100\n",
      "Created a chunk of size 186, which is longer than the specified 100\n",
      "Created a chunk of size 217, which is longer than the specified 100\n",
      "Created a chunk of size 231, which is longer than the specified 100\n",
      "Created a chunk of size 206, which is longer than the specified 100\n",
      "Created a chunk of size 1020, which is longer than the specified 100\n",
      "Created a chunk of size 216, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n",
      "Created a chunk of size 967, which is longer than the specified 100\n",
      "Created a chunk of size 186, which is longer than the specified 100\n",
      "Created a chunk of size 957, which is longer than the specified 100\n",
      "Created a chunk of size 212, which is longer than the specified 100\n",
      "Created a chunk of size 201, which is longer than the specified 100\n",
      "Created a chunk of size 212, which is longer than the specified 100\n",
      "Created a chunk of size 180, which is longer than the specified 100\n",
      "Created a chunk of size 1019, which is longer than the specified 100\n",
      "Created a chunk of size 219, which is longer than the specified 100\n",
      "Created a chunk of size 234, which is longer than the specified 100\n",
      "Created a chunk of size 198, which is longer than the specified 100\n",
      "Created a chunk of size 241, which is longer than the specified 100\n",
      "Created a chunk of size 193, which is longer than the specified 100\n",
      "Created a chunk of size 225, which is longer than the specified 100\n",
      "Created a chunk of size 242, which is longer than the specified 100\n",
      "Created a chunk of size 216, which is longer than the specified 100\n",
      "Created a chunk of size 208, which is longer than the specified 100\n",
      "Created a chunk of size 140, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크1:\n",
      "page_content='2024년 11월호' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 0}\n",
      "\n",
      "청크2:\n",
      "page_content='2024년 11월호' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 1}\n",
      "\n",
      "청크3:\n",
      "page_content='Ⅰ. 인공지능 산업 동향 브리프 1. 정책/법제    ▹ 미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석························1   ▹ 미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표·····························2   ▹ 유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간··············································3   ▹ OECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표··························································4   ▹ 세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시····················································5  2. 기업/산업    ▹ CB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중··············6   ▹ 메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개···································································7   ▹ 메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개···························8   ▹ 앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개····9   ▹ 미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스트로’ 공개·················································10   ▹ 카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개···············································11 3. 기술/연구   ▹ 2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상············································12   ▹ 미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표························13   ▹ 일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간········································14   ▹ 구글 딥마인드, 반도체 칩 레이아웃 설계하는 AI 모델 ‘알파칩’ 발표·····························15   ▹ AI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조····························16    4. 인력/교육        ▹ MIT 산업성과센터, 근로자 관점에서 자동화 기술의 영향 조사········································17   ▹ 다이스 조사, AI 전문가의 73%는 2025년 중 이직 고려················································18   ▹ 가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요 ·····························19   ▹ 인디드 조사 결과, 생성AI가 인간 근로자 대체할 가능성은 희박·····································20' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 1}\n",
      "\n",
      "청크4:\n",
      "page_content='Ⅱ. 주요 행사  ▹NeurIPS 2024 ······················································································································21  ▹GenAI Summit Maroc 2024 ·····························································································21  ▹AI Summit Seoul 2024 ·····································································································21' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 1}\n",
      "\n",
      "청크5:\n",
      "page_content='Ⅰ. 인공지능 산업 동향 브리프' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 2}\n",
      "\n",
      "청크6:\n",
      "page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "1' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 3}\n",
      "\n",
      "청크7:\n",
      "page_content='미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석n미국 민권위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되고 있으나 이를 관리할 지침과 감독의 부재로 민권 문제를 초래할 위험 존재n미국 민권위원회는 연방정부의 책임 있는 얼굴인식 기술 사용을 위해 운영 프로토콜 개발과 실제 사용 상황의 얼굴인식 기술 평가 및 불평등 완화, 지역사회의 의견 수렴 등을 권고' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 3}\n",
      "\n",
      "청크8:\n",
      "page_content='KEY Contents' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 3}\n",
      "\n",
      "청크9:\n",
      "page_content='£연방정부의 얼굴인식 기술 도입에 대한 지침과 감독 부재로 민권 문제를 초래할 위험 존재n미국 민권위원회(U.S. Commission on Civil Rights)가 2024년 9월 19일 연방정부의 얼굴인식 기술 사용이 민권에 미치는 영향을 분석한 보고서를 발간∙AI 기술의 일종인 얼굴인식 기술은 연방정부와 법 집행기관에서 빠르게 도입되고 있으며, 일례로 법무부 연방수사국(FBI)은 범죄 수사 및 용의자 수색용 단서 확보를 위해 얼굴인식 기술을 가장 빈번히 사용∙그러나 얼굴인식 기술의 책임 있는 사용을 위한 연방 지침과 감독은 실제 활용 사례보다 뒤처졌으며, 현재 연방정부의 얼굴인식 기술이나 여타 AI 기술 사용을 명시적으로 규제하는 법률도 부재  n보고서에 따르면 얼굴인식 기술의 무분별한 사용은 편향, 개인정보 침해, 적법 절차의 미준수 및 차별적 영향과 같은 민권 문제를 초래할 위험 보유∙얼굴인식 기술의 정확도는 인종, 성별, 연령 등 인구통계학적 요인에 따라 달라질 수 있으며, 이는 식별 오류 및 부정확한 체포로 이어져 유색인종을 비롯한 특정 집단에 차별적 결과를 초래할 위험 존재∙정부 기관이 사전 영장이나 정당한 이유 없이 얼굴인식 기술을 광범위하게 사용할 경우 개인을 지속적으로 추적하고 감시함으로써 개인정보 보호 권리에 심각한 영향을 미칠 위험 존재∙법 집행기관의 얼굴인식 기술 사용 시 부정확한 식별 및 편향으로 인해 개인이 법의 보호를 받아 공정하고 올바르게 대우받을 권리를 침해할 가능성도 존재£민권위원회, 연방정부의 책임 있는 얼굴인식 기술 사용을 위한 권고사항 제시n민권위원회는 연방정부의 얼굴인식 기술 사용과 관련해 다음과 같은 권고사항을 제시∙국립표준기술연구소(NIST)는 정부 기관의 얼굴인식 기술 시스템 도입 시의 효과와 공평성, 정확성 평가에 사용할 수 있는 운영 테스트 프로토콜의 개발 필요∙각 연방정부 기관의 최고AI책임자는 실제 사용 상황에서 얼굴인식 기술을 평가하고 차별이나 편견으로 인한 불평등을 완화하며, 얼굴인식 기술의 사용으로 영향을 받는 지역사회의 의견을 수렴 필요∙얼굴인식 기술 제공업체는 다양한 인구통계 집단에 대한 높은 정확도를 보장하기 위해 지속적인 교육과 지원, 업데이트를 제공 필요 ☞ 출처: U.S. Commission on Civil Rights, The Civil Rights Implications of the Federal Use of Facial Recognition Technology, 2024.09.19.' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 3}\n",
      "\n",
      "청크10:\n",
      "page_content='SPRi AI Brief |  2024-11월호\n",
      "2' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 4}\n",
      "\n",
      "청크11:\n",
      "page_content='미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 4}\n",
      "\n",
      "청크12:\n",
      "page_content='KEY Contents' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 4}\n",
      "\n",
      "청크13:\n",
      "page_content='£백악관 예산관리국, 연방정부의 AI 조달 시 책임성을 증진하기 위한 모범 관행 제시n미국 백악관 예산관리국(OMB)이 바이든 대통령의 AI 행정명령에 따른 후속 조치로 2024년 10월 3일 ‘정부의 책임 있는 AI 조달 지침(M-24-18)’을 발표∙미국 연방정부는 2023년 1,000억 달러 이상의 IT 제품과 서비스를 구매한 미국 경제 최대 규모의 단일 구매자로서 구매력을 활용해 책임 있는 AI의 발전을 뒷받침할 계획∙이번 지침은 △AI 위험과 성과 관리 △AI 시장의 경쟁 촉진 △연방정부 전반의 협업 보장이라는 3개 전략적 목표에 대하여 권고사항을 제시n(AI 위험과 성과 관리) 예산관리국의 지침은 AI 시스템의 구축, 훈련, 배포 방식의 복잡성을 고려해 AI의 위험과 성과를 관리하기 위한 모범 관행을 다음과 같이 제시∙정부 기관의 개인정보 보호 담당자가 AI 조달 프로세스에 조기에 지속적으로 참여해 개인정보 보호 위험을 식별 및 관리하고 법률과 정책 준수를 보장∙정부 기관과 공급업체와 간 협력으로 AI 솔루션이 조달되는 시기와 해당 조달로 인해 시민 권리와 안전에 영향을 미치는 AI에 대하여 추가로 위험관리가 필요한 시점을 파악∙성과 기반의 혁신적 조달 기법을 활용해 정부 기관이 위험을 효과적으로 관리 및 완화하고 성과를 향상할 수 있도록 장려하는 한편, 정부 데이터와 지식재산권을 보호하는 방식으로 계약 조건을 협상 n(AI 시장의 경쟁 촉진) 지침은 정부 기관이 최상의 AI 솔루션을 사용할 수 있도록 공급업체 시장에서 강력한 경쟁을 보장할 것을 요구  ∙계약 요건 수립 시 공급업체 의존성을 최소화할 수 있는 인수 원칙을 적용하고, 시장 조사와 요구사항 개발, 공급업체 평가 절차에서 상호운용성과 투명성을 고려하며, 혁신적 조달 관행을 활용해 우수한 계약업체 성과와 정부 기관의 임무 성과를 보장n(연방정부 전반의 협업 보장) 빠르게 발전하는 AI 기술환경의 위험관리를 위해 AI 전문지식을 갖춘 공무원과 조달, 개인정보보호, 사이버보안 전문가를 포함하는 협업 팀을 구성해 전략적 조달을 지원  ∙각 정부 기관은 기관 간 협의회를 구성해 효과적이고 책임 있는 AI 조달을 지원하고, 협업 시 기관 목표에 가장 적합한 AI 투자 식별 및 우선순위 지정, AI 배포 역량 개발, AI 모범 활용 사례 채택 증진 등을 고려☞ 출처: The White House, FACT SHEET: OMB Issues Guidance to Advance the Responsible Acquisition of AI in Government, 2024.10.03.' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 4}\n",
      "\n",
      "청크14:\n",
      "page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "3' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 5}\n",
      "\n",
      "청크15:\n",
      "page_content='유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간n유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유n그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이 필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 5}\n",
      "\n",
      "청크16:\n",
      "page_content='KEY Contents' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 5}\n",
      "\n",
      "청크17:\n",
      "page_content='£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현을 위한 고려사항 제시nEU 사법기관 유로폴(Europol)이 2024년 9월 24일 법 집행에서 효과적 범죄 퇴치를 위한 AI의 활용 가능성을 탐색한 보고서를 발간∙보고서는 법 집행에서 AI 기술을 윤리적이고 투명하게 구현하기 위한 지침 역할을 하며, AI의 이점과 과제를 함께 다룸으로써 법 집행에서 AI 사용 시 윤리적 고려 사항에 대한 인식 제고를 추구n보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석, 생체인식 시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유∙법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI 도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능 ∙기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적n그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및 다양한 윤리적·사회적 우려도 존재∙일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의 무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요∙데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터 규모와 운영 요구사항에 적응할 수 있는 확장성과 성능을 갖춘 AI 모델도 개발 필요∙편향, 개인정보 침해와 인권 침해와 같은 다양한 윤리적·사회적 우려도 존재하며, 이를 해소하기 위해 데이터 편향을 제거하고 공공 안전과 개인정보 간 균형을 유지하며 AI 의사 결정 과정에 대한 투명성과 책임성을 보장 필요n보고서는 2024년 8월 발효된 EU AI 법이 법 집행기관에 미칠 영향도 분석∙EU AI 법은 공공장소에서 실시간 생체인식 식별과 같은 특정 애플리케이션의 사용을 금지하고 고위험 AI 시스템에 엄격한 감독을 부과하였으나 법 집행 활동의 특수성을 고려해 일부 예외를 설정 ∙그러나 일부 예외에도 법 집행 역량 강화를 위한 AI 사용을 위해서는 기존에 도입한 AI 시스템에 대한 재평가와 수정이 필요한 만큼, 재정과 인력 측면의 상당한 부담 예상☞ 출처: Europol, AI and policing-The benefits and challenges of artificial intelligence for law enforcement, 2024.09.24.' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 5}\n",
      "\n",
      "청크18:\n",
      "page_content='SPRi AI Brief |  2024-11월호\n",
      "4' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 6}\n",
      "\n",
      "청크19:\n",
      "page_content='OECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표nOECD는 공공 부문에서 EU 및 G7 국가들의 AI 도입 모범사례와 거버넌스 프레임워크, 정책 옵션을 토대로 공공 부문의 AI 도입을 안내하는 보고서를 발표n보고서는 공공 부문의 AI 도입 시 프로토타입부터 시작해 시범 도입을 거쳐 본격적으로 구현하는 단계별 접근방식을 권고' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 6}\n",
      "\n",
      "청크20:\n",
      "page_content='KEY Contents' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 6}\n",
      "\n",
      "청크21:\n",
      "page_content='£OECD, G7의 사례를 토대로 공공 부문의 AI 도입을 안내하는 지침 마련nOECD가 2024년 10월 15일 안전하고 신뢰할 수 있는 AI의 원칙을 실행 가능한 정책으로 전환할 수 있도록 지원하는 ‘공공 부문의 AI를 위한 G7 툴킷’ 보고서를 발간∙OECD는 G7 회원국이 작성한 설문 응답 및 OECD와 UNESCO의 연구를 토대로 공공 부문에서 AI 활용 모범사례와 거버넌스 프레임워크, 정책 옵션과 관련된 종합적 지침 제공을 목표로 보고서를 작성nG7과 EU의 AI 도입 추세를 분석한 결과, G7 회원국과 EU는 공공 부문의 AI 도입과 관련된 국가 전략 및 정책의 개발과 구현에서 차이가 존재  ∙EU·독일·미국·영국·일본은 국가 AI 전략에 공공 부문을 포함했고 프랑스는 국가 AI 전략에서는 공공 부문을 구체적으로 다루지 않으나 공공행정 혁신기금(FTAP)을 조성하여 60개 이상의 AI 프로젝트에 투자하는 등 별도의 정책을 수립∙캐나다는 2025년 봄까지 공공 서비스를 위한 AI 전략을 개발할 계획이며, 이탈리아는 ‘공공 부문 디지털화를 위한 3개년 계획(2024~2026)’에 AI를 포함 ∙G7 회원국들은 접근방식의 차이에도 인재와 기술 개발, 조달 정책, 협력관계 구축, 윤리적이고 신뢰할 수 있으며 인간 중심적인 AI 관행 조성, 데이터 품질 보장 등에서 공통점을 보유nAI 거버넌스 프레임워크 측면에서 G7 회원국 중 미국·캐나다·프랑스와 EU는 여러 기관이 AI를 관리하는 분산형 거버넌스 구조를 채택했으며 이탈리아·독일·영국은 단일 기관이 AI를 관리하는 중앙집중형 거버넌스를 채택nG7 회원국들은 공공 부문의 운영 효율성 향상, 정책 결정 강화, 공공 서비스 개선, 정부의 투명성과 책임성 강화를 위해 AI를 활용하는 한편, 다양한 정책 옵션으로 AI 도입 시의 과제 해결을 모색∙AI 도입에 필수적인 인프라를 강화하기 위한 데이터 저장과 공유 솔루션 채택, AI에 적합한 혁신적이고 유연한 조달 절차의 수립 및 민간 파트너십 육성, 공공 부문의 AI 역량 강화, 데이터 거버넌스 프레임워크 구축 등이 대표적인 정책 옵션n보고서는 공공 부문의 AI 도입 시 각 단계를 신중히 관리하여 위험을 완화할 수 있도록, 문제를 명확히 정의하고 아이디어를 구상한 뒤 프로토타입부터 시작해 통제된 환경에서 AI를 시범 도입한 후 이를 개선해 본격적으로 구현하는 단계적 접근방식을 강조☞ 출처: OECD, G7 Toolkit for Artificial Intelligence in the Public Sector, 2024.10.15.' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 6}\n",
      "\n",
      "청크22:\n",
      "page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "5' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 7}\n",
      "\n",
      "청크23:\n",
      "page_content='세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시n세계경제포럼이 글로벌 정책입안자를 대상으로 생성AI의 공익적 활용과 경제·사회적 균형 달성, 위험 완화를 위한 거버넌스 프레임워크를 제안하는 백서를 발표n백서에 따르면 정부는 기존 규제를 평가해 생성AI로 인한 규제 격차를 해소하는 한편, 다양한 이해관계자 간 지식 공유를 촉진하고 미래의 AI 발전에 대비한 규제 민첩성을 갖출 필요' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 7}\n",
      "\n",
      "청크24:\n",
      "page_content='KEY Contents' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 7}\n",
      "\n",
      "청크25:\n",
      "page_content='£생성AI 거버넌스, 과거-현재-미래를 아우르는 프레임워크 수립 필요n세계경제포럼(WEF)이 2024년 10월 8일 세계 각국의 정책입안자를 대상으로 생성AI 거버넌스 프레임워크를 제시한 백서를 발간∙백서는 생성AI의 공익적 활용과 경제·사회적 균형 달성, 위험 완화라는 목표 달성을 위해 △과거 활용(Harness Past) △현재 구축(Build Present) △미래 계획(Plan Future)의 프레임워크를 제안n(과거 활용) 기존 규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI 규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요∙생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를 고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완∙기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제 권한을 집중하는 방안의 장단점을 고려n(현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는 정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적∙정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자 집단의 고유한 문제에 대응 필요∙다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재n(미래 계획) 생성AI 거버넌스에 대한 민첩한 준비와 함께 국제협력을 촉진하는 것으로, 정부는 빠른 기술 발전과 한정된 자원, 글로벌 불확실성을 고려해 미래를 예견한 국가 전략을 개발하고 다음의 활동을 추진∙정부 내 AI 역량 향상과 AI 전문가 채용을 위한 투자를 시행하고 AI 전담 기관의 설립 필요성을 신중히 검토∙생성AI와 인간 간 상호작용, 생성AI와 여타 기술의 융합, 생성AI 신기능과 관련된 혁신 및 이로 인한 새로운 위험을 탐색 ∙기존 규제의 영향 평가 및 미래 AI 발전에 대비한 영향 평가로 규제 민첩성을 유지하며, 일례로 광범위한 도입에 앞서 규제 유예제도(샌드박스)를 시범 운영∙지식과 인프라 공유와 AI 안전성 연구, AI 표준의 일관성 확보를 위한 국제협력 추진☞ 출처: World Economic Forum, Governance in the Age of Generative AI: A 360° Approach for Resilient Policy and Regulation, 2024.10.08.' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 7}\n",
      "\n",
      "청크26:\n",
      "page_content='SPRi AI Brief |  2024-11월호\n",
      "6' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 8}\n",
      "\n",
      "청크27:\n",
      "page_content='CB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중nCB인사이츠에 따르면 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며, AI 스타트업의 투자금 회수 시점은 일반 기업보다 6년 빠른 것으로 확인n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 오픈AI와 같은 거대 기업도 비용 통제에 어려움을 겪고 있다며 상당수 AI 스타트업이 실패할 것으로 예상' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 8}\n",
      "\n",
      "청크28:\n",
      "page_content='KEY Contents' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 8}\n",
      "\n",
      "청크29:\n",
      "page_content='£AI 스타트업, 벤처 투자의 최우선 고려 대상으로 부상n글로벌 리서치 기업 CB인사이츠(CB Insights)가 2024년 10월 3일 발표한 2024년 3분기 벤처 현황 보고서에 따르면 2024년 3분기 벤처 자금의 31%가 AI 스타트업에 투자된 것으로 분석  ∙AI 스타트업은 2024년 2분기에 전체 벤처 투자의 35%를 유치하며 역대 최고 비중을 차지했으며, 3분기에도 역대 두 번째로 높은 비중을 기록∙오픈AI의 공동설립자 일리야 수츠케버(Ilya Sutskever)가 2024년 6월 설립한 스타트업 SSI(Safe Superintelligence Inc.)는 10억 달러를 유치하며 3분기 대표적인 AI 투자로 기록∙CB인사이츠가 전 세계 1만 5천 개 이상의 AI 스타트업을 추적한 결과, 전 세계 AI 스타트업의 43%가 미국 기업이며, 다음 순위는 중국이 9%, 영국이 7%, 인도와 캐나다가 각각 4%로 미국과 상당한 격차를 기록n기업가치 10억 달러 이상의 유니콘 기업은 2024년 3분기에 24개가 탄생했으며, 이중 절반 이상이 AI 기업인 것으로 확인∙범용 로봇 개발기업 스킬드AI(Skild AI), 공간지능에 특화된 월드랩스(World Labs), 법률 AI 서비스 기업 하비(Harvey) 등이 유니콘 지위를 획득nAI 스타트업은 투자금 회수(Exit) 시점도 일반 스타트업보다 훨씬 빨라 AI 기업이 엑시트하는 시점은 설립 후 7년에 불과했으나 여타 스타트업은 13년 소요되었으며, 이러한 경향은 M&A에서 가장 뚜렷해 2024년 AI 스타트업 엑시트는 대부분 M&A를 통해 달성∙대기업들은 자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고 있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는 2024년 9월 AI 스타트업 2곳을 인수n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에 부응하지 못하고 실패하게 될 것으로 예상∙CB인사이츠는 오픈AI와 같은 거대 AI 기업조차도 수익을 내지 못해 비용을 통제해야 하는 어려움을 겪고 있다며, 오픈AI의 2024년 손실 규모가 50억 달러에 달할 것으로 전망☞ 출처 : CB Insights, State of Venture Q3’24 Report, 2024.10.03.' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 8}\n",
      "\n",
      "청크30:\n",
      "page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "7' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 9}\n",
      "\n",
      "청크31:\n",
      "page_content='메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개n메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는 ‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획n메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁 동영상 AI 모델보다 더 높은 점수를 기록' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 9}\n",
      "\n",
      "청크32:\n",
      "page_content='KEY Contents' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 9}\n",
      "\n",
      "청크33:\n",
      "page_content='£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개 n메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타 무비 젠(Meta Movie Gen)’을 공개∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을 반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과 같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침n메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대 16초 길이 동영상 생성을 지원∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을 반영한 개인화 동영상을 제작 가능∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과 같은 광범위한 수정도 지원∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로 최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가n메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를 비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 9}\n",
      "\n",
      "청크34:\n",
      "page_content='<메타 무비 젠과 경쟁 AI 모델의 인간 선호도 평가 승률>' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 9}\n",
      "\n",
      "청크35:\n",
      "page_content='☞ 출처: Meta, How Meta Movie Gen could usher in a new AI-enabled era for content creators, 2024.10.04.' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 9}\n",
      "\n",
      "청크36:\n",
      "page_content='SPRi AI Brief |  2024-11월호\n",
      "8' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 10}\n",
      "\n",
      "청크37:\n",
      "page_content='메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개n메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량 모델을 포함하는 라마 3.2 시리즈를 공개n비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서 앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 10}\n",
      "\n",
      "청크38:\n",
      "page_content='KEY Contents' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 10}\n",
      "\n",
      "청크39:\n",
      "page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 10}\n",
      "\n",
      "청크40:\n",
      "page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\n",
      "9' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 11}\n",
      "\n",
      "청크41:\n",
      "page_content='앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개n앨런AI연구소가 공개한 멀티모달 LLM 제품군 몰모는 벤치마크 평가에서 GPT-4o를 능가하는 성능의 72B 모델과 전문가혼합 모델, 온디바이스 모델 등 4개 모델로 구성n몰모-72B 모델은 시각적 이해 능력이 뛰어나며 벤치마크 평가 및 인간 선호도 평가에서 첨단 폐쇄형 모델을 능가하는 점수를 기록' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 11}\n",
      "\n",
      "청크42:\n",
      "page_content='KEY Contents £몰모-72B 모델, 벤치마크 평가에서 GPT-4o와 제미나이 1.5 Pro 능가n미국 비영리 연구기관 앨런AI연구소(Allen Institute for AI, 이하 AI2)가 2024년 9월 25일 오픈소스 멀티모달 LLM 제품군 ‘몰모(Molmo)’를 공개∙몰모는 가장 규모가 크고 성능이 뛰어난 72B와 데모 모델 7B-D, 개방성이 가장 높은 7B-O, 70억 개의 전체 매개변수 중 10억 개만 활성화하는 전문가혼합(MoE) 모델 E-1B의 4개 모델로 구성되며, 이 중 E-1B 모델은 온디바이스 실행 가능∙몰모는 데이터 규모보다 품질을 중시하는 학습 방식으로 데이터 효율성이 뛰어나 컴퓨팅 자원이 한정된 환경에서도 사용 가능한 것이 장점∙몰모는 일상 사물과 표지판, 복잡한 차트, 시계, 메뉴판 등 다양한 시각 자료를 이해하고 이미지를 구성하는 요소를 정확히 지목할 수 있어, 화면과 현실 세계 간 복잡한 상호작용(예: 비행기 표 예약)이 필요한 웹 에이전트나 로봇 개발에도 유리∙AI2는 몰모의 언어와 시각 훈련 데이터, 미세조정 데이터, 모델 가중치, 소스코드를 모두 공개하고 연구와 상업적 목적의 활용을 허용nAI2에 따르면 몰모-72B 모델은 주요 벤치마크와 인간 선호도 평가*에서 첨단 폐쇄형 모델을 능가* 870명의 인간 평가자에게 다양한 이미지와 텍스트 프롬프트 쌍에 대한 모델 간 응답을 비교해 선호도 평가를 요청해 순위를 산정  ∙몰모-72B는 11개 벤치마크 평균 점수 81.2점으로 ‘GPT-4o’(78.5점), ‘제미나이 1.5 Pro’(78.3점), ‘클로드-3.5 소네트’(76.7점)를 넘는 최고 점수를 기록했으며 인간 선호도 평가에서는 1077점으로 GPT-4o(1079점)에 이어 2위∙전문가혼합 모델인 몰모E-1B는 벤치마크 평균 점수에서 68.6점, 인간 선호도 평가는 1,032점으로 각각 71.1점과 1,041점을 받은 GPT-4V과 경쟁할 수 있는 수준' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 11}\n",
      "\n",
      "청크43:\n",
      "page_content='<몰모 제품군과 GPT-4o/GPT-4V의 벤치마크 평균(左)과 인간 선호도 평가(右) 점수 비교>' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 11}\n",
      "\n",
      "청크44:\n",
      "page_content='☞ 출처: Allen Institute for AI, Introducing Molmo, 2024.09.25.' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 11}\n",
      "\n",
      "청크45:\n",
      "page_content='SPRi AI Brief |  2024-11월호\n",
      "10' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 12}\n",
      "\n",
      "청크46:\n",
      "page_content='미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스트로’ 공개n미스트랄AI가 네트워크 연결 없이 온디바이스로 사용할 수 있는 경량 모델 ‘레 미니스트로’를 미스트랄 3B와 미스트랄 8B 버전으로 공개n벤치마크 평가에서 레 미니스트로는 비슷한 매개변수를 가진 오픈소스 모델 젬마 및 라마와 비교해 대부분 벤치마크에서 더 높은 평가를 획득' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 12}\n",
      "\n",
      "청크47:\n",
      "page_content='KEY Contents' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 12}\n",
      "\n",
      "청크48:\n",
      "page_content='£미스트랄 AI, 네트워크 연결이 필요 없는 경량 모델 ‘레 미니스트로’ 출시 n프랑스의 대표 AI 스타트업 미스트랄AI(Mistral AI)가 2024년 10월 16일 네트워크 연결 없이 작동하는 온디바이스용 AI 모델 ‘레 미니스트로(Les Ministraux)’를 발표∙ ‘미스트랄 3B’와 ‘미스트랄 8B’ 버전으로 공개된 이 모델은 경량 모델이면서도 영어책 50쪽 분량에 해당하는 12만 8천 개 토큰의 컨텍스트 창을 지원∙미스트랄AI는 레 미니스트로가 번역과 스마트 어시스턴트, 분석, 자율 로봇 같은 중요 애플리케이션에 대하여 네트워크 연결 없이 개인정보보호가 가능한 온디바이스 추론을 원하는 고객 수요에 맞게 지연시간이 짧고 효율적인 솔루션을 제공한다고 강조∙미스트랄AI는 8B 버전만 연구용으로 다운로드를 허용했으며 향후 두 모델을 클라우드 플랫폼을 통해 제공할 계획으로, 사용 비용은 100만 입출력 토큰 당 8B 버전은 10센트, 3B 버전은 4센트로 책정£레 미니스트로, 오픈소스 모델 ‘젬마’ 및 ‘라마’ 대비 대부분 벤치마크에서 우수한 평가n벤치마크 평가 결과, 레 미니스트로는 비슷한 매개변수를 가진 오픈소스 모델 젬마(Gemma)와 라마(Llama)보다 대부분 벤치마크에서 더 높은 평가를 획득∙MMLU* 평가에서 미스트랄 3B는 60.9점을 얻어 구글의 ‘젬마 2 2B’(52.4점)와 메타의 ‘라마 3.2 3B’(56.2점)를 앞섰고, 미스트랄 8B는 65.0점으로 ‘라마 3.1 8B’(64.7점)와 1년 전 출시된 자체 모델 ‘미스트랄 7B’(62.5점)를 능가 * 다양한 주제에 대한 모델의 광범위한 지식과 추론 능력을 평가하는 벤치마크∙미스트랄 8B는 코딩 능력을 평가하는 HumanEval pass@1*에서만 34.8점으로 ‘라마 3.1 8B’(37.8점)보다 소폭 낮은 점수를 기록* AI 모델이 한 번의 시도로 정확한 코드를 생성할 수 있는 능력을 평가하는 벤치마크' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 12}\n",
      "\n",
      "청크49:\n",
      "page_content='<미스트랄 3B/7B와 경쟁 모델의 벤치마크 평가 비교>' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 12}\n",
      "\n",
      "청크50:\n",
      "page_content='☞ 출처: Mistral AI, Un Ministral, des Ministraux-Introducing the world’s best edge models, 2024.10.16.' metadata={'source': '/Users/ohhalim/git_box/TIL/llm/개인과제_데이터/인공지능산업최신동향_2024년11월호.pdf', 'page': 12}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "문서 청크로 나누기\n",
    "아래 코드는 문서를 청크 단위로 나누는 함수입니다.\n",
    "저는 CharacterTextSplitter를 사용하겠습니다. \n",
    "RecursiveCharacterTextSplitter는 다음 코드에 독스트링으로만 남겨 두겠습니다.\n",
    "'''\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    # 줄바꿈을 기준으로 분할합니다\n",
    "    chunk_size=100,\n",
    "    # 텍스트를 처리하기 쉬운 작은 조각으로 나누는 크기\n",
    "    chunk_overlap=20\n",
    "    # chunks 간의 문맥 유지를 위한 중복 크기\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "# 입력받은 데이터(pages)를 나눔\n",
    "# 나눈 결과를 리스트로 반환\n",
    "\n",
    "for i, chunk in enumerate(chunks[:50]):\n",
    "    print(f\"청크{i + 1}:\\n{chunk}\\n\")\n",
    "# 리스트 chunks의 첫 50개 요소를 순회하면서, 각 요소(chunk)와 그에 해당하는 인덱스(i)를 가져옵니다\n",
    "# enumerate(): 반복 중 현재 인덱스와 값을 동시에 가져오는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b6e066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n사용하지 않을 RRecursiveCharacterTextSplitter\\n\\n- RRecursiveCharacterTextSplitter 설정\\n\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\n\\ntext_splitter = RecursiveCharacterTextSplitter(\\n    separators=[\"\\n\", \".\", \" \"], # 우선순위 정하기: 줄바꿈 > 점 > 공백\\n    chunk_size=100, # 청크 최대 크기\\n    chunk_overlap=20 # 청크 간 겹치는 크기\\n)\\n\\nchunks = text_splitter.split_documents(pages)\\n\\nfor i, chunk in enumerate(chunks[:50]):\\n    print(f\"청크{i + 1}:\\n{chunk}\\n\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "사용하지 않을 RRecursiveCharacterTextSplitter\n",
    "\n",
    "- RRecursiveCharacterTextSplitter 설정\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\", \".\", \" \"], # 우선순위 정하기: 줄바꿈 > 점 > 공백\n",
    "    chunk_size=100, # 청크 최대 크기\n",
    "    chunk_overlap=20 # 청크 간 겹치는 크기\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "for i, chunk in enumerate(chunks[:50]):\n",
    "    print(f\"청크{i + 1}:\\n{chunk}\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ea17e-b00e-4610-87c9-2edf5702067e",
   "metadata": {},
   "source": [
    "\n",
    "-------------------------------------------\n",
    "**문서 청크로 나누기**\n",
    "\n",
    "불러온 문서를 대상으로 아래 i, ii 청킹방법을 모두 수행하세요.\n",
    "청킹을 완수하면 청킹된 내용을 상위 50개까지 출력하고, 각 청킹방식과 parameter의 뜻을 markdown으로 정리해주세요.\n",
    "\n",
    "-----------------------------\n",
    "> 청킹된 내용 상위 50개를 출력하였는가?\n",
    "\n",
    "네\n",
    "\n",
    "for i, chunk in enumerate(chunks[:50]):\n",
    "    print(f\"청크{i + 1}:\\n{chunk}\\n\") 로 출력함.\n",
    "\n",
    "---------------------------------\n",
    "> 각 청킹방식과 parameter의 뜻은?\n",
    "\n",
    "1. CharacterTextSplitter 청킹 방식\n",
    "\n",
    "각 파라미터의 뜻\n",
    "    separator=\"\\n\"  줄바꿈을 기준으로 텍스트를 나눔\n",
    "    chunk_size=100, 각 청크사이즈는 최대 100개\n",
    "    chunk_overlap=20 청크간 겹치는 문자의 개수는 최대 20개\n",
    "\n",
    "\n",
    "2. RecursiveCharacterTextSplitter 청킹 방식\n",
    "\n",
    "CharacterTextSplitter보다 더 세밀하게 텍스트를 나눌 수 있는 LangChain의 텍스트 분할 도구\n",
    "문맥을 유지하는 청킹작업에 유용하다 함\n",
    "\n",
    "\n",
    "각 파라미터의 뜻\n",
    "    separators=[\"\\n\", \".\", \" \"], # 우선순위 정하기: 줄바꿈 > 점 > 공백\n",
    "    chunk_size=100, # 청크 최대 크기\n",
    "    chunk_overlap=20 # 청크 간 겹치는 크기\n",
    "    \n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "189ac052-8dcc-4553-971b-a0a2ad3e3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "백터 임베딩 생성 \n",
    "OpenAI 모델이므로 OpenAIEmbeddings을 이용해 벡터 임베딩 생성\n",
    "\"\"\"\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "# LangChain 라이브러리의 embeddings 모듈에서 OpenAIEmbeddings 클래스를 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dbfd17e-2af7-4d1b-a9c6-87363a41f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "벡터 스토어 생성\n",
    "앞서 만든 벡터 임베딩과 청크된 문서를 활용하여 `FAISS` 벡터 스토어 생성\n",
    "\"\"\"\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# FAISS 벡터 스토어 생성\n",
    "vectorstore = FAISS.from_documents(\n",
    "    # from_documents()는 FAISS 클래스의 클래스 메서드(class method)로, LangChain에서 제공하는 FAISS 벡터스토어를 생성하기 위한 기본 함수입니다.\n",
    "    # documents, embedding 파라미터를 받아서 faiss 인덱스를 생성 한다\n",
    "    # 인덱스는 백터들의 저장소임, 특정정보를 빠르게 찾을수있게 해줌\n",
    "    documents=chunks,  # 청크된 문서\n",
    "    embedding=embeddings  # OpenAI 임베딩\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "446b1f3c-a5a3-47eb-8316-618b234a70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FAISS를 Retriever로 변환\n",
    "RAG 체인에서 사용할 수 있도록 FAISS를 `retriever`로 변환하세요\n",
    "\"\"\"\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "\n",
    "# as_retriever() 메서드\n",
    "# 벡터 스토어 객체를 retriever 객체로 변환하는 메서드입니다\n",
    "# 문서 검색을 수행할 수 있는 인터페이스를 제공합니다.\n",
    "# search_type=\"similarity\" 파라미터\n",
    "# 검색 방식을 지정하는 파라미터입니다\n",
    "# \"similarity\": 벡터 간 유사도 기반 검색을 수행\n",
    "# search_kwargs={\"k\": 1} 파라미터\n",
    "# 검색 관련 추가 매개변수를 딕셔너리 형태로 전달\n",
    "# \"k\": 검색할 결과의 개수를 지정\n",
    "# 여기서는 k=1로 설정되어 가장 유사한 문서 1개만 반환\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eab51f26-05c4-41b8-885d-3636401cc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "프롬프트 템플릿 정의\n",
    "프롬프트 템플릿은 다양한 입력을 받아 메시지를 생성하는데 도움을 준다.\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    # 템플릿에 들어갈 변수들을 리스트로 지정 (\"context\"와 \"question\")\n",
    "    template=f\"\"\"{system_template}\n",
    "\n",
    "참고 문서 내용:\n",
    "{{context}}\n",
    "\n",
    "질문: {{question}}\n",
    "\n",
    "답변:\"\"\"\n",
    ")\n",
    "    # {context}: 문서 내용이 들어갈 자리 {question}: 질문이 들어갈 자리\n",
    "\n",
    "# 시스템 메시지 설정\n",
    "system_template = \"\"\" 답변 정보를 어디서 가져왔는지 알려주고, 다음 가이드라인을 따라주세요:\n",
    "- 신뢰할 수 있는 출처를 인용해주세요\n",
    "- 정보의 출처를 명확히 표시해주세요\n",
    "- 가능한 경우 여러 출처를 제시해주세요\"\"\" \n",
    "# 시스템 메시지는 AI가 대화를 어떻게 진행할지를 결정하는 지침 역할을 합니다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d3f5ec6-c51b-459a-8497-e6f81818ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "RAG 체인 구성\n",
    "LangChain의 모델과 프롬프트를 연결하여 RAG 체인을 구성\n",
    "\"\"\"\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "            #RAG 시스템을 구성하는 체인(chain)을 생성하는 메서드\n",
    "    llm=model,\n",
    "    # 사용할 언어 모델 (Large Language Model) 인스턴스\n",
    "    retriever=retriever,\n",
    "    # 문서를 검색하는 retriever 객체\n",
    "    chain_type=\"stuff\",\n",
    "    # 체인의 타입. \"stuff\"는 모든 컨텍스트를 한 번에 프롬프트에 넣는 방식\n",
    "\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")   # prompt: 위에서 정의한 PromptTemplate 인스턴스\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "543f05e1-f458-4e86-a81d-e0245fb093d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ai 최신정보를 알려줘 \n",
      "최신 AI 정보에 대해 제공할 수 있는 몇 가지 주제를 소개합니다. 이러한 정보는 여러 신뢰할 수 있는 출처에서 얻어진 것입니다.\n",
      "\n",
      "1. **AI Summit Seoul 2024**:\n",
      "   - **행사 개요**: AI Summit Seoul은 2018년부터 개최되었으며, 2024년에는 12월 10일부터 11일까지 서울 코엑스 그랜드볼룸에서 열릴 예정입니다. 이 행사에서는 AI와 산업의 융합을 주제로 다양한 글로벌 기업 및 전문가들이 모여 주제 발표와 워크샵을 진행합니다.\n",
      "   - **출처**: [AI Summit 공식 홈페이지](https://aisummit.co.kr/)\n",
      "\n",
      "2. **AI 안전성 평가 가이드**:\n",
      "   - **일본 AI안전연구소**: 일본 AI안전연구소는 AI 개발자 및 제공자를 위한 'AI 안전성에 대한 평가 관점 가이드'를 발간했습니다. 이 가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 효과적 조치를 통해 기대할 수 있는 목표를 제시합니다.\n",
      "   - **출처**: 일본 AI안전연구소 공식 발표\n",
      "\n",
      "3. **AI 기술 동향**:\n",
      "   - **Generative AI의 발전**: OpenAI, Google, Microsoft 등 주요 기업들이 Generative AI 기술을 활용하여 콘텐츠 생성, 이미지 합성 등 다양한 분야에서 혁신을 이끌고 있습니다. 이러한 기술은 교육, 마케팅, 헬스케어 등 여러 산업에 큰 영향을 미치고 있습니다.\n",
      "   - **출처**: [Forbes](https://www.forbes.com/), [MIT Technology Review](https://www.technologyreview.com/)\n",
      "\n",
      "4. **AI 윤리 및 규제**:\n",
      "   - **EU AI 법안**: 유럽연합은 AI 기술의 안전성과 윤리를 보장하기 위해 AI 법안을 제정하고 있습니다. 이 법안은 다양한 AI 응용 분야에 대한 규제를 포함하며, AI 시스템의 투명성과 책임성을 강조합니다.\n",
      "   - **출처**: [European Commission](https://ec.europa.eu/), [The Verge](https://www.theverge.com/)\n",
      "\n",
      "이와 같은 정보는 AI의 최신 동향을 이해하는 데 도움이 될 수 있습니다. 각 출처를 통해 더 깊이 있는 내용을 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "챗봇구동 확인\n",
    "질문에 답변하는 챗봇을 구현하여 작동 시키세요\n",
    "rag 왜 필요한지 마크 다운으로 서술 하세요\n",
    "\"\"\"\n",
    "\n",
    "query = input(\"\")\n",
    "print(f\" {query} \") \n",
    "# 입력받은 질문은 query 변수에 저장\n",
    "response = rag_chain.run(query)\n",
    "# 설정한 RAG 체인을 실행합니다\n",
    "# retriever가 질문과 관련된 문서들을 검색\n",
    "# 검색된 문서들과 질문이 프롬프트 템플릿에 삽입\n",
    "# LLM이 최종 답변을 생성        \n",
    "# response에 저장\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8d905-b52f-4a09-b7f8-fdf138e60908",
   "metadata": {},
   "source": [
    "**rag 왜 필요한지 마크 다운으로 서술 하세요**\n",
    "\n",
    "openai api에 업데이트 되지 않은 정보를 내가 rag를 통해 입력해서 정보를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159608ef",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020c5e02",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
